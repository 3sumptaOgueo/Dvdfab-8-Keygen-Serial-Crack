// Copyright (C) 2009-2023, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki mutator HZB_TEST 0 1
#pragma anki mutator DISTANCE_TEST 0 1
#pragma anki mutator GATHER_AABBS 0 1
#pragma anki mutator HASH_VISIBLES 0 1
#pragma anki mutator GATHER_TYPE 1 2 3

#pragma anki skip_mutation DISTANCE_TEST 1 HZB_TEST 1

#define GATHER_MDI (GATHER_TYPE & 1u)
#define GATHER_MESHLET_GROUPS (GATHER_TYPE & 2u)

#pragma anki technique_start comp

#include <AnKi/Shaders/Common.hlsl>
#include <AnKi/Shaders/Include/GpuSceneTypes.h>
#include <AnKi/Shaders/Include/GpuVisibilityTypes.h>
#include <AnKi/Shaders/VisibilityAndCollisionFunctions.hlsl>

struct DrawIndirectArgsWithPadding
{
	U32 m_vertexCount;
	U32 m_instanceCount;
	U32 m_firstVertex;
	U32 m_firstInstance;
	U32 m_padding;
};

// Buffers that point to the GPU scene
StructuredBuffer<GpuSceneRenderableBoundingVolume> g_renderableBoundingVolumes : register(t0);
StructuredBuffer<GpuSceneRenderable> g_renderables : register(t1);
StructuredBuffer<GpuSceneMeshLod> g_meshLods : register(t2);
StructuredBuffer<Mat3x4> g_transforms : register(t3);
ByteAddressBuffer g_gpuScene : register(t4);

#if GATHER_MDI
// These 3 have the same size
RWStructuredBuffer<UVec4> g_instanceRateRenderables : register(u0);
RWStructuredBuffer<DrawIndexedIndirectArgs> g_drawIndexedIndirectArgs : register(u1);
RWStructuredBuffer<DrawIndirectArgsWithPadding> g_drawIndirectArgs : register(u2);

// The MDI counts. One for each render state bucket
RWStructuredBuffer<U32> g_mdiDrawCounts : register(u3);
#endif

#if GATHER_MESHLET_GROUPS
// For mesh shading
RWStructuredBuffer<DispatchIndirectArgs> g_taskShaderIndirectArgs : register(u4);
RWStructuredBuffer<GpuSceneMeshletGroupInstance> g_meshletGroupInstances : register(u5);
#endif

// One for each render state bucket. It's either the index of the next indirect args or the index to the next task payload
StructuredBuffer<UVec2> g_instanceRanges : register(t5);

#if DISTANCE_TEST == 0
ConstantBuffer<FrustumGpuVisibilityUniforms> g_unis : register(b0);
#else
ANKI_PUSH_CONSTANTS(DistanceGpuVisibilityUniforms, g_unis)
#endif

#if HZB_TEST
Texture2D<Vec4> g_hzbTex : register(t6);
SamplerState g_nearestAnyClampSampler : register(s0);
#endif

#if GATHER_AABBS
RWStructuredBuffer<U32> g_visibleAabbIndices : register(u6); ///< Indices of the visible AABBs. The 1st element is the count.
#endif

#if HASH_VISIBLES
RWStructuredBuffer<GpuVisibilityHash> g_hash : register(u7);
#endif

[numthreads(64, 1, 1)] void main(UVec3 svDispatchThreadId : SV_DISPATCHTHREADID)
{
	const U32 bvolumeIdx = svDispatchThreadId.x;
	U32 bvolumeCount;
	U32 unused;
	g_renderableBoundingVolumes.GetDimensions(bvolumeCount, unused);
	if(bvolumeIdx >= bvolumeCount)
	{
		return;
	}

	const GpuSceneRenderableBoundingVolume bvolume = g_renderableBoundingVolumes[bvolumeIdx];

	const Vec3 sphereCenter = (bvolume.m_aabbMin + bvolume.m_aabbMax) * 0.5f;
	const F32 sphereRadius = bvolume.m_sphereRadius;

#if DISTANCE_TEST == 0
	// Frustum test
	//
	if(!frustumTest(g_unis.m_clipPlanes, sphereCenter, sphereRadius))
	{
		return;
	}

	// Screen-space AABB calculation and checking
	//
	Vec2 minNdc, maxNdc;
	F32 aabbMinDepth;
	projectAabb(bvolume.m_aabbMin, bvolume.m_aabbMax, g_unis.m_viewProjectionMat, minNdc, maxNdc, aabbMinDepth);

	if(any(minNdc > 1.0f) || any(maxNdc < -1.0f))
	{
		// Outside of the screen
		return;
	}

	const Vec2 windowCoordsMin = ndcToUv(minNdc) * g_unis.m_finalRenderTargetSize;
	const Vec2 windowCoordsMax = ndcToUv(maxNdc) * g_unis.m_finalRenderTargetSize;
	if(any(round(windowCoordsMin) == round(windowCoordsMax)))
	{
		// Doesn't touch the sampling points
		return;
	}

	// HiZ culling
	//
#	if HZB_TEST
	if(cullHzb(minNdc, maxNdc, aabbMinDepth, g_hzbTex, g_nearestAnyClampSampler))
	{
		return;
	}
#	endif // HZB_TEST

#else // DISTANCE_TEST == 1
	if(!testSphereSphereCollision(sphereCenter, sphereRadius, g_unis.m_pointOfTest, g_unis.m_testRadius))
	{
		return;
	}
#endif

	// Compute the LOD
	//
	const F32 distFromLodPoint = length(sphereCenter - g_unis.m_lodReferencePoint) - sphereRadius;

	U32 lod;
	if(distFromLodPoint < g_unis.m_maxLodDistances[0])
	{
		lod = 0u;
	}
	else if(distFromLodPoint < g_unis.m_maxLodDistances[1])
	{
		lod = 1u;
	}
	else
	{
		lod = 2u;
	}

	// Add the drawcall
	//
	const U32 renderStateBucket = bvolume.m_renderableIndex_20bit_renderStateBucket_12bit & ((1u << 12u) - 1u);
	const U32 renderableIdx = bvolume.m_renderableIndex_20bit_renderStateBucket_12bit >> 12u;

	const GpuSceneRenderable renderable = g_renderables[renderableIdx];
	const U32 meshLodIndex = renderable.m_meshLodsIndex + lod;
	const GpuSceneMeshLod meshLod = g_meshLods[meshLodIndex];

	const Bool isParticleEmitter = renderable.m_particleEmitterOffset != 0;
	ANKI_MAYBE_UNUSED(isParticleEmitter);

	const Bool usesMeshShaders = meshLod.m_meshletCount != 0u;
	if(usesMeshShaders)
	{
#if GATHER_MESHLET_GROUPS
		const U32 meshletGroupCount = (meshLod.m_meshletCount + (kMeshletGroupSize - 1u)) / kMeshletGroupSize;

		U32 instanceIdx;
		InterlockedAdd(g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountX, meshletGroupCount, instanceIdx);

		if(instanceIdx == 0u)
		{
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountY = 1u;
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountZ = 1u;
		}
		else if(instanceIdx >= g_instanceRanges[renderStateBucket].y)
		{
			// Reached a memory limit, cancel the job
			ANKI_ASSERT(0);
			instanceIdx = 0;
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountY = 0u;
		}

		instanceIdx += g_instanceRanges[renderStateBucket].x;

		// Divide the mesh into meshlet groups and add them as task payloads
		GpuSceneMeshletGroupInstance instance;
		instance.m_lod_2bit_renderableIdx_21bit_meshletGroup_9bit = (lod << 30u) | (renderableIdx << 9u);

		for(U32 i = 0; i < meshletGroupCount; ++i)
		{
			g_meshletGroupInstances[instanceIdx + i] = instance;

			++instance.m_lod_2bit_renderableIdx_21bit_meshletGroup_9bit;
		}
#endif
	}
	else
	{
#if GATHER_MDI
		U32 bucketDrawcallIdx;
		InterlockedAdd(g_mdiDrawCounts[renderStateBucket], 1, bucketDrawcallIdx);

		if(bucketDrawcallIdx >= g_instanceRanges[renderStateBucket].y)
		{
			// OoM, ignore
			ANKI_ASSERT(0);
			U32 orig;
			InterlockedExchange(g_mdiDrawCounts[renderStateBucket], g_instanceRanges[renderStateBucket].y, orig);
		}
		else
		{
			const U32 indirectIdx = bucketDrawcallIdx + g_instanceRanges[renderStateBucket].x;
			if(!isParticleEmitter)
			{
				// Regular renderables are always indexed

				DrawIndexedIndirectArgs indirect;
				indirect.m_indexCount = meshLod.m_indexCount;
				indirect.m_instanceCount = 1;
				indirect.m_firstIndex = meshLod.m_firstIndex;
				indirect.m_vertexOffset = 0;
				indirect.m_firstInstance = bucketDrawcallIdx;
				g_drawIndexedIndirectArgs[indirectIdx] = indirect;

				UVec4 instanceVertex;
				instanceVertex.x = renderable.m_worldTransformsIndex;
				instanceVertex.y = renderable.m_uniformsOffset;
				instanceVertex.z = meshLodIndex;
				instanceVertex.w = renderable.m_boneTransformsOffset;
				g_instanceRateRenderables[indirectIdx] = instanceVertex;
			}
			else
			{
				const GpuSceneParticleEmitter emitter = g_gpuScene.Load<GpuSceneParticleEmitter>(renderable.m_particleEmitterOffset);

				DrawIndirectArgsWithPadding indirect;
				indirect.m_vertexCount = emitter.m_aliveParticleCount * meshLod.m_indexCount;
				indirect.m_instanceCount = 1;
				indirect.m_firstVertex = 0;
				indirect.m_firstInstance = bucketDrawcallIdx;
				indirect.m_padding = 0;
				g_drawIndirectArgs[indirectIdx] = indirect;

				UVec4 instanceVertex;
				instanceVertex.x = renderable.m_worldTransformsIndex;
				instanceVertex.y = renderable.m_uniformsOffset;
				instanceVertex.z = meshLodIndex;
				instanceVertex.w = renderable.m_particleEmitterOffset;
				g_instanceRateRenderables[indirectIdx] = instanceVertex;
			}
		}
#endif
	}

#if HASH_VISIBLES
	// Update the renderables hash
	{
		// Transform a random point as a way to get a feel for the transform
		const Mat3x4 trf = g_transforms[renderable.m_worldTransformsIndex];
		const Vec3 pt = mul(trf, Vec4(1503.98f, 2006.8f, -1400.16f, 1.0f));
		const UVec3 ptu = UVec3(asuint(pt.x), asuint(pt.y), asuint(pt.z));

		U32 hash = ptu.x;
		hash ^= ptu.y;
		hash ^= ptu.z;
		hash ^= renderable.m_uuid;

		InterlockedXor(g_hash[0].m_renderablesHash, hash);

		const Bool deformable = isParticleEmitter || renderable.m_boneTransformsOffset != 0;
		if(deformable)
		{
			g_hash[0].m_containsDeformable = 1;
		}
	}
#endif

#if GATHER_AABBS
	U32 index;
	InterlockedAdd(g_visibleAabbIndices[0], 1, index);
	g_visibleAabbIndices[index + 1] = bvolumeIdx;
#endif
}

#pragma anki technique_end comp
