// Copyright (C) 2009-2023, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki mutator HZB_TEST 0 1
#pragma anki mutator DISTANCE_TEST 0 1
#pragma anki mutator GATHER_AABBS 0 1
#pragma anki mutator HASH_VISIBLES 0 1

#pragma anki skip_mutation DISTANCE_TEST 1 HZB_TEST 1

#pragma anki start comp

#include <AnKi/Shaders/Common.hlsl>
#include <AnKi/Shaders/Include/GpuSceneTypes.h>
#include <AnKi/Shaders/Include/GpuVisibilityTypes.h>
#include <AnKi/Shaders/VisibilityAndCollisionFunctions.hlsl>

struct DrawIndirectArgsWithPadding
{
	U32 m_vertexCount;
	U32 m_instanceCount;
	U32 m_firstVertex;
	U32 m_firstInstance;
	U32 m_padding;
};

// Buffers that point to the GPU scene
[[vk::binding(0)]] StructuredBuffer<GpuSceneRenderableBoundingVolume> g_renderableBoundingVolumes;
[[vk::binding(1)]] StructuredBuffer<GpuSceneRenderable> g_renderables;
[[vk::binding(2)]] ByteAddressBuffer g_gpuScene;

// These 3 have the same size
[[vk::binding(3)]] RWStructuredBuffer<UVec4> g_instanceRateRenderables;
[[vk::binding(4)]] RWStructuredBuffer<DrawIndexedIndirectArgs> g_drawIndexedIndirectArgs;
[[vk::binding(4)]] RWStructuredBuffer<DrawIndirectArgsWithPadding> g_drawIndirectArgs;

// The MDI counts. One for each render state bucket
[[vk::binding(5)]] RWStructuredBuffer<U32> g_mdiDrawCounts;

// For mesh shading
[[vk::binding(6)]] RWStructuredBuffer<DispatchIndirectArgs> g_taskShaderIndirectArgs;
[[vk::binding(7)]] RWStructuredBuffer<GpuSceneTaskShaderPayload> g_taskShaderPayloads;

// One for each render state bucket. It's either the index of the next indirect args or the index to the next task payload
[[vk::binding(8)]] StructuredBuffer<U32> g_drawIndirectArgsIndexOrTaskPayloadIndex;

#if DISTANCE_TEST == 0
[[vk::binding(9)]] ConstantBuffer<FrustumGpuVisibilityConstants> g_consts;
#else
[[vk::push_constant]] ConstantBuffer<DistanceGpuVisibilityConstants> g_consts;
#endif

#if HZB_TEST
[[vk::binding(10)]] Texture2D<Vec4> g_hzbTex;
[[vk::binding(11)]] SamplerState g_nearestAnyClampSampler;
#endif

#if GATHER_AABBS
[[vk::binding(12)]] RWStructuredBuffer<U32> g_visibleAabbIndices; ///< Indices of the visible AABBs. The 1st element is the count.
#endif

#if HASH_VISIBLES
[[vk::binding(13)]] RWStructuredBuffer<GpuVisibilityHash> g_hash;
#endif

[numthreads(64, 1, 1)] void main(UVec3 svDispatchThreadId : SV_DISPATCHTHREADID)
{
	const U32 bvolumeIdx = svDispatchThreadId.x;
	U32 bvolumeCount;
	U32 unused;
	g_renderableBoundingVolumes.GetDimensions(bvolumeCount, unused);
	if(bvolumeIdx >= bvolumeCount)
	{
		return;
	}

	const GpuSceneRenderableBoundingVolume bvolume = g_renderableBoundingVolumes[bvolumeIdx];

	const Vec3 sphereCenter = (bvolume.m_aabbMin + bvolume.m_aabbMax) * 0.5f;
	const F32 sphereRadius = bvolume.m_sphereRadius;

#if DISTANCE_TEST == 0
	// Frustum test
	//
	if(!frustumTest(g_consts.m_clipPlanes, sphereCenter, sphereRadius))
	{
		return;
	}

	// Screen-space AABB calculation and checking
	//
	Vec2 minNdc, maxNdc;
	F32 aabbMinDepth;
	projectAabb(bvolume.m_aabbMin, bvolume.m_aabbMax, g_consts.m_viewProjectionMat, minNdc, maxNdc, aabbMinDepth);

	if(any(minNdc > 1.0f) || any(maxNdc < -1.0f))
	{
		// Outside of the screen
		return;
	}

	const Vec2 windowCoordsMin = ndcToUv(minNdc) * g_consts.m_finalRenderTargetSize;
	const Vec2 windowCoordsMax = ndcToUv(maxNdc) * g_consts.m_finalRenderTargetSize;
	if(any(round(windowCoordsMin) == round(windowCoordsMax)))
	{
		// Doesn't touch the sampling points
		return;
	}

	// HiZ culling
	//

#	if HZB_TEST
	// Compute the mip
	Vec2 texSize;
	F32 mipCount;
	g_hzbTex.GetDimensions(0, texSize.x, texSize.y, mipCount);

	const Vec2 minUv = saturate(ndcToUv(minNdc));
	const Vec2 maxUv = saturate(ndcToUv(maxNdc));
	const Vec2 sizeXY = (maxUv - minUv) * texSize;
	F32 mip = ceil(log2(max(sizeXY.x, sizeXY.y)));

	// Try to use a more detailed mip if you can
	const F32 levelLower = max(mip - 1.0, 0.0);
	const Vec2 mipSize = texSize / pow(2.0f, levelLower);
	const Vec2 a = floor(minUv * mipSize);
	const Vec2 b = ceil(maxUv * mipSize);
	const Vec2 dims = b - a;

	if(dims.x <= 2.0 && dims.y <= 2.0)
	{
		mip = levelLower;
	}

	// Sample mip
	Vec4 depths;
	depths[0] = g_hzbTex.SampleLevel(g_nearestAnyClampSampler, minUv, mip);
	depths[1] = g_hzbTex.SampleLevel(g_nearestAnyClampSampler, maxUv, mip);
	depths[2] = g_hzbTex.SampleLevel(g_nearestAnyClampSampler, Vec2(minUv.x, maxUv.y), mip);
	depths[3] = g_hzbTex.SampleLevel(g_nearestAnyClampSampler, Vec2(maxUv.x, minUv.y), mip);
	const F32 maxDepth = max4(depths);

	if(aabbMinDepth > maxDepth)
	{
		return;
	}
#	endif // HZB_TEST
#else // DISTANCE_TEST == 1
	if(!testSphereSphereCollision(sphereCenter, sphereRadius, g_consts.m_pointOfTest, g_consts.m_testRadius))
	{
		return;
	}
#endif

	// Compute the LOD
	//
	const F32 distFromLodPoint = length(sphereCenter - g_consts.m_lodReferencePoint) - sphereRadius;

	U32 lod;
	if(distFromLodPoint < g_consts.m_maxLodDistances[0])
	{
		lod = 0u;
	}
	else if(distFromLodPoint < g_consts.m_maxLodDistances[1])
	{
		lod = 1u;
	}
	else
	{
		lod = 2u;
	}

	// Add the drawcall
	//
	const U32 renderStateBucket = bvolume.m_renderableIndex_20bit_renderStateBucket_12bit & ((1u << 12u) - 1u);
	const U32 renderableIdx = bvolume.m_renderableIndex_20bit_renderStateBucket_12bit >> 12u;

	const GpuSceneRenderable renderable = g_renderables[renderableIdx];
	const U32 meshLodOffset = renderable.m_meshLodsOffset + sizeof(GpuSceneMeshLod) * lod;
	const GpuSceneMeshLod meshLod = g_gpuScene.Load<GpuSceneMeshLod>(meshLodOffset);

	const Bool isParticleEmitter = renderable.m_particleEmitterOffset != 0;
	const Bool usesMeshShaders = meshLod.m_meshletCount != 0u;

	if(usesMeshShaders)
	{
		const U32 meshletGroupCount = (meshLod.m_meshletCount + (kMeshletGroupSize - 1u)) / kMeshletGroupSize;

		U32 payloadIdx;
		InterlockedAdd(g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountX, meshletGroupCount, payloadIdx);

		if(payloadIdx == 0u)
		{
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountY = 1u;
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountZ = 1u;
		}
		else if(payloadIdx >= kMaxMeshletGroupCountPerRenderStateBucket)
		{
			// Reached a memory limit, cancel the job
			ANKI_ASSERT(0);
			payloadIdx = 0;
			g_taskShaderIndirectArgs[renderStateBucket].m_threadGroupCountY = 0u;
		}

		payloadIdx += g_drawIndirectArgsIndexOrTaskPayloadIndex[renderStateBucket];

		// Divide the mesh into meshlet groups and add them as task payloads
		GpuSceneTaskShaderPayload payload;
		payload.m_lod_2bit_renderableIdx_21bit_meshletGroup_9bit = (lod << 30u) | (renderableIdx << 9u);

		for(U32 i = 0; i < meshletGroupCount; ++i)
		{
			g_taskShaderPayloads[payloadIdx + i] = payload;

			++payload.m_lod_2bit_renderableIdx_21bit_meshletGroup_9bit;
		}
	}
	else
	{
		U32 indirectIdx;
		InterlockedAdd(g_mdiDrawCounts[renderStateBucket], 1, indirectIdx);
		indirectIdx += g_drawIndirectArgsIndexOrTaskPayloadIndex[renderStateBucket];

		if(!isParticleEmitter)
		{
			// Regular renderables are always indexed

			DrawIndexedIndirectArgs indirect;
			indirect.m_indexCount = meshLod.m_indexCount;
			indirect.m_instanceCount = 1;
			indirect.m_firstIndex = meshLod.m_firstIndex;
			indirect.m_vertexOffset = 0;
			indirect.m_firstInstance = indirectIdx;
			g_drawIndexedIndirectArgs[indirectIdx] = indirect;

			UVec4 instanceVertex;
			instanceVertex.x = renderable.m_worldTransformsOffset;
			instanceVertex.y = renderable.m_constantsOffset;
			instanceVertex.z = meshLodOffset;
			instanceVertex.w = renderable.m_boneTransformsOffset;
			g_instanceRateRenderables[indirectIdx] = instanceVertex;
		}
		else
		{
			const GpuSceneParticleEmitter emitter = g_gpuScene.Load<GpuSceneParticleEmitter>(renderable.m_particleEmitterOffset);

			DrawIndirectArgsWithPadding indirect;
			indirect.m_vertexCount = emitter.m_aliveParticleCount * meshLod.m_indexCount;
			indirect.m_instanceCount = 1;
			indirect.m_firstVertex = 0;
			indirect.m_firstInstance = indirectIdx;
			g_drawIndirectArgs[indirectIdx] = indirect;

			UVec4 instanceVertex;
			instanceVertex.x = renderable.m_worldTransformsOffset;
			instanceVertex.y = renderable.m_constantsOffset;
			instanceVertex.z = meshLodOffset;
			instanceVertex.w = renderable.m_particleEmitterOffset;
			g_instanceRateRenderables[indirectIdx] = instanceVertex;
		}
	}

#if HASH_VISIBLES
	// Update the renderables hash
	{
		const Mat3x4 trf = g_gpuScene.Load<Mat3x4>(renderable.m_worldTransformsOffset);
		const Vec3 pos = trf.getTranslationPart();
		const UVec3 posu = UVec3(asuint(pos.x), asuint(pos.y), asuint(pos.z));

		U32 hash = posu.x;
		hash ^= posu.y;
		hash ^= posu.z;
		hash ^= renderable.m_uuid;

		InterlockedXor(g_hash[0].m_renderablesHash, hash);

		const Bool deformable = isParticleEmitter || renderable.m_boneTransformsOffset != 0;
		if(deformable)
		{
			g_hash[0].m_containsDeformable = 1;
		}
	}
#endif

#if GATHER_AABBS
	U32 index;
	InterlockedAdd(g_visibleAabbIndices[0], 1, index);
	g_visibleAabbIndices[index + 1] = bvolumeIdx;
#endif
}

#pragma anki end comp
