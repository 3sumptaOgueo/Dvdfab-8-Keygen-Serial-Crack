// Copyright (C) 2009-2023, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

// Ground truth ambiend occlusion

#pragma anki mutator SAMPLE_COUNT 3 5 7 9 11 13 15

#include <AnKi/Shaders/Common.hlsl>

// ===========================================================================
// SSAO                                                                      =
// ===========================================================================
#if ANKI_TECHNIQUE_Ssao && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)
#	include <AnKi/Shaders/Include/MiscRendererTypes.h>
#	include <AnKi/Shaders/Functions.hlsl>
#	include <AnKi/Shaders/PackFunctions.hlsl>
#	include <AnKi/Shaders/FastMathFunctions.hlsl>
#	include <AnKi/Shaders/ImportanceSampling.hlsl>

[[vk::binding(0)]] Texture2D<Vec4> g_gbufferRt2;
[[vk::binding(1)]] Texture2D<Vec4> g_depthTex;

[[vk::binding(2)]] Texture2D<RVec4> g_noiseTex;
[[vk::binding(3)]] SamplerState g_trilinearRepeatSampler;
[[vk::binding(4)]] SamplerState g_linearAnyClampSampler;

[[vk::binding(5)]] Texture2D<RVec4> g_historyTex;
[[vk::binding(6)]] Texture2D<Vec4> g_motionVectorsTex;
[[vk::binding(7)]] Texture2D<RVec4> g_historyLengthTex;

#	if ANKI_COMPUTE_SHADER
[[vk::binding(8)]] RWTexture2D<RVec4> g_outUav;
#	endif

[[vk::push_constant]] ConstantBuffer<SsaoConstants> g_consts;

Vec3 unproject(Vec2 ndc)
{
	const F32 d = g_depthTex.SampleLevel(g_linearAnyClampSampler, ndcToUv(ndc), 0.0).r;
	return cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, ndc, d);
}

Vec4 project(Vec4 p)
{
	return cheapPerspectiveProjection(g_consts.m_projectionMat00, g_consts.m_projectionMat11, g_consts.m_projectionMat22, g_consts.m_projectionMat23,
									  p);
}

RF32 computeFalloff(RF32 len)
{
	return sqrt(1.0f - min(1.0f, len / g_consts.m_radius));
}

#	if ANKI_COMPUTE_SHADER
[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
#	else
RF32 main([[vk::location(0)]] Vec2 uv : TEXCOORD, Vec4 svPosition : SV_POSITION) : SV_TARGET0
#	endif
{
#	if ANKI_COMPUTE_SHADER
	const Vec2 uv = (Vec2(svDispatchThreadId) + 0.5) / g_consts.m_viewportSizef;
#	else
	const UVec2 svDispatchThreadId = svPosition;
	ANKI_MAYBE_UNUSED(svDispatchThreadId);
#	endif

	const Vec2 ndc = uvToNdc(uv);
	const Vec3 Pc = unproject(ndc);
	const RVec3 V = normalize(-Pc); // View vector

	// Get noise
#	if 0
	Vec2 noiseTexSize;
	g_noiseTex.GetDimensions(noiseTexSize.x, noiseTexSize.y);
	const RVec2 noiseUv = Vec2(g_consts.m_viewportSizef) / noiseTexSize * uv;
	const RVec2 noise2 = animateBlueNoise(g_noiseTex.SampleLevel(g_trilinearRepeatSampler, noiseUv, 0.0).xyz, g_consts.m_frameCount).yx;
#	else
	const RVec2 noise2 = spatioTemporalNoise(svDispatchThreadId, g_consts.m_frameCount);
#	endif

	// Rand slice direction
	const RF32 randAng = noise2.x * kPi;
#	if 0
	const RF32 aspect = g_consts.m_viewportSizef.x / g_consts.m_viewportSizef.y;
	const RVec2 dir2d = normalize(Vec2(cos(randAng), sin(randAng)) * Vec2(1.0f, aspect));
#	else
	const RVec2 dir2d = Vec2(cos(randAng), sin(randAng));
#	endif

	// Project the view normal to the slice
	const Vec3 worldNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_linearAnyClampSampler, uv, 0.0));
	const RVec3 viewNormal = mul(g_consts.m_viewMat, Vec4(worldNormal, 0.0));

	const RVec3 directionVec = RVec3(dir2d, 0.0f);
	const RVec3 orthoDirectionVec = directionVec - (dot(directionVec, V) * V);
	const RVec3 axisVec = normalize(cross(orthoDirectionVec, V));
	const RVec3 projectedNormalVec = viewNormal - axisVec * dot(viewNormal, axisVec);
	const RF32 signNorm = (F32)sign(dot(orthoDirectionVec, projectedNormalVec));
	const RF32 projectedNormalVecLength = length(projectedNormalVec);
	const RF32 cosNorm = saturate(dot(projectedNormalVec, V) / projectedNormalVecLength);
	const RF32 n = -signNorm * fastAcos(cosNorm);

	// Find the projected radius
	const Vec3 sphereLimit = Pc + Vec3(g_consts.m_radius, 0.0, 0.0);
	const Vec4 projSphereLimit = project(Vec4(sphereLimit, 1.0));
	const Vec2 projSphereLimit2 = projSphereLimit.xy / projSphereLimit.w;
	const RF32 projRadius = length(projSphereLimit2 - ndc);

	// Compute the inner integral (Slide 54)
	const U32 stepCount = max(1u, g_consts.m_sampleCount / 2u);

	const RF32 lowHorizonCos1 = cos(n - kPi / 2.0f);
	const RF32 lowHorizonCos2 = cos(n + kPi / 2.0f);

	RF32 cosH1 = lowHorizonCos1;
	RF32 cosH2 = lowHorizonCos2;

	for(U32 i = 0u; i < stepCount; ++i)
	{
		const RF32 stepBaseNoise = RF32(i * stepCount) * 0.6180339887498948482;
		const RF32 stepNoise = frac(noise2.y + stepBaseNoise);
		RF32 s = (i + stepNoise) / RF32(stepCount);
		s *= s;
		const Vec2 sampleOffset = dir2d * projRadius * s;

		// h1
		const Vec3 Ps = unproject(ndc + sampleOffset);
		const Vec3 Ds = Ps - Pc;
		const RF32 DsLen = length(Ds);
		cosH1 = max(cosH1, lerp(lowHorizonCos1, dot(V, Ds) / DsLen, computeFalloff(DsLen)));

		// h2
		const Vec3 Pt = unproject(ndc - sampleOffset);
		const Vec3 Dt = Pt - Pc;
		const RF32 DtLen = length(Dt);
		cosH2 = max(cosH2, lerp(lowHorizonCos2, dot(V, Dt) / DtLen, computeFalloff(DtLen)));
	}

	// Compute the h1 and h2
	const RF32 h1 = n + max(-fastAcos(cosH1) - n, -kPi / 2);
	const RF32 h2 = n + min(fastAcos(cosH2) - n, kPi / 2);

	// Compute the final value (Slide 61)
	RF32 Vd = -cos(2.0f * h1 - n) + cos(n) + 2.0f * h1 * sin(n);
	Vd += -cos(2.0f * h2 - n) + cos(n) + 2.0f * h2 * sin(n);
	Vd *= 0.25;
	Vd *= projectedNormalVecLength;

	// Apply power
	Vd = pow(Vd, g_consts.m_ssaoPower);

	// Blend color with history
	{
		const Vec2 historyUv = uv + g_motionVectorsTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0f).xy;

		// History length creates black trails so it doesn't work correctly
#	if 0
		const RVec4 historyLengths = g_historyLengthTex.GatherRed(g_linearAnyClampSampler, uv + g_consts.m_prevJitterUv);
		const RF32 historyLength = max4(historyLengths);
#	else
		const RF32 historyLength = (any(historyUv < 0.0f) || any(historyUv > 1.0f)) ? 0.0f : 1.0f;
#	endif

		const RF32 lowestBlendFactor = 0.1f;
		const RF32 maxHistoryLength = 16.0f;
		const RF32 stableFrames = 4.0f;
		const RF32 lerpVal = min(1.0f, (historyLength * maxHistoryLength - 1.0f) / stableFrames);
		const RF32 blendFactor = lerp(1.0f, lowestBlendFactor, lerpVal);

		// Blend with history
		if(blendFactor < 1.0)
		{
			const RF32 history = g_historyTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f).r;
			Vd = lerp(history, Vd, blendFactor);
		}
	}

#	if ANKI_COMPUTE_SHADER
	g_outUav[svDispatchThreadId] = Vd;
#	else
	return Vd;
#	endif
}
#endif // ANKI_TECHNIQUE_Ssao && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)

// ===========================================================================
// SSAO denoise                                                              =
// ===========================================================================
#if(ANKI_TECHNIQUE_SsaoDenoiseVertical || ANKI_TECHNIQUE_SsaoDenoiseHorizontal) && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)
#	include <AnKi/Shaders/BilateralFilter.hlsl>

[[vk::binding(0)]] SamplerState g_linearAnyClampSampler;
[[vk::binding(1)]] Texture2D<RVec4> g_inTex;
[[vk::binding(2)]] Texture2D<Vec4> g_depthTex;

#	if ANKI_COMPUTE_SHADER
[[vk::binding(3)]] RWTexture2D<RVec4> g_outImg;
#	endif

F32 readDepth(Vec2 uv)
{
	return g_depthTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0).x;
}

void sampleTex(Vec2 uv, F32 refDepth, inout RF32 col, inout RF32 weight)
{
	const RF32 color = g_inTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0).x;
	const RF32 w = calculateBilateralWeightDepth(refDepth, readDepth(uv), 1.0f);
	col += color * w;
	weight += w;
}

#	if ANKI_COMPUTE_SHADER
[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
#	else
F32 main([[vk::location(0)]] Vec2 uv : TEXCOORD) : SV_TARGET0
#	endif
{
	UVec2 textureSize;
	U32 mipCount;
	g_inTex.GetDimensions(0, textureSize.x, textureSize.y, mipCount);

	// Set UVs
#	if ANKI_COMPUTE_SHADER
	const Vec2 uv = (Vec2(svDispatchThreadId) + 0.5) / Vec2(textureSize);
#	endif

	const Vec2 texelSize = 1.0 / Vec2(textureSize);

	// Sample
	RF32 color = g_inTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0).r;
	const F32 refDepth = readDepth(uv);
	RF32 weight = 1.0;

#	if ANKI_TECHNIQUE_SsaoDenoiseHorizontal
#		define X_OR_Y x
#	else
#		define X_OR_Y y
#	endif

	Vec2 uvOffset = 0.0f;
	uvOffset.X_OR_Y = 1.0f * texelSize.X_OR_Y;

	[unroll] for(U32 i = 0u; i < (SAMPLE_COUNT - 1u) / 2u; ++i)
	{
		sampleTex(uv + uvOffset, refDepth, color, weight);
		sampleTex(uv - uvOffset, refDepth, color, weight);

		uvOffset.X_OR_Y += 1.0f * texelSize.X_OR_Y;
	}

	color /= weight;

	// Write value
#	if ANKI_COMPUTE_SHADER
	g_outImg[svDispatchThreadId] = color;
#	else
	return color;
#	endif
}
#endif // (ANKI_TECHNIQUE_SsaoDenoiseVertical || ANKI_TECHNIQUE_SsaoDenoiseHorizontal) && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)

// ===========================================================================
// Techniques                                                                =
// ===========================================================================
#pragma anki technique_start vert Ssao uses_mutators
#include <AnKi/Shaders/QuadVert.hlsl>
#pragma anki technique_end vert Ssao

#pragma anki technique_start frag Ssao uses_mutators
#pragma anki technique_end frag Ssao

#pragma anki technique_start comp Ssao
#pragma anki technique_end comp Ssao

#pragma anki technique_start vert SsaoDenoiseVertical
#include <AnKi/Shaders/QuadVert.hlsl>
#pragma anki technique_end vert SsaoDenoiseVertical

#pragma anki technique_start frag SsaoDenoiseVertical
#pragma anki technique_end frag SsaoDenoiseVertical

#pragma anki technique_start comp SsaoDenoiseVertical
#pragma anki technique_end comp SsaoDenoiseVertical

#pragma anki technique_start vert SsaoDenoiseHorizontal
#include <AnKi/Shaders/QuadVert.hlsl>
#pragma anki technique_end vert SsaoDenoiseHorizontal

#pragma anki technique_start frag SsaoDenoiseHorizontal
#pragma anki technique_end frag SsaoDenoiseHorizontal

#pragma anki technique_start comp SsaoDenoiseHorizontal
#pragma anki technique_end comp SsaoDenoiseHorizontal
