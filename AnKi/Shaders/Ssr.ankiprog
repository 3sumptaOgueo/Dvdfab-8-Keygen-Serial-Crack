// Copyright (C) 2009-2023, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

// Screen space reflections

#include <AnKi/Shaders/Common.hlsl>

// ===========================================================================
// SSR                                                                       =
// ===========================================================================
#if defined(__INTELLISENSE__)
#	define ANKI_TECHNIQUE_Ssr 1
#endif

#if ANKI_TECHNIQUE_Ssr && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)
#	include <AnKi/Shaders/Include/MiscRendererTypes.h>
#	include <AnKi/Shaders/Functions.hlsl>
#	include <AnKi/Shaders/PackFunctions.hlsl>
#	include <AnKi/Shaders/FastMathFunctions.hlsl>
#	include <AnKi/Shaders/ImportanceSampling.hlsl>
#	include <AnKi/Shaders/SsRaymarching.hlsl>

#	define EXTRA_REJECTION 1

[[vk::binding(0)]] ConstantBuffer<SsrConstants> g_consts;

[[vk::binding(1)]] SamplerState g_trilinearClampSampler;
[[vk::binding(2)]] Texture2D<RVec4> g_gbufferRt1;
[[vk::binding(3)]] Texture2D<RVec4> g_gbufferRt2;
[[vk::binding(4)]] Texture2D<Vec4> g_depthRt;
[[vk::binding(5)]] Texture2D<RVec4> g_lightBufferRt;

#	if ANKI_COMPUTE_SHADER
[[vk::binding(6)]] RWTexture2D<RVec4> g_outUav;
#	endif

ANKI_BINDLESS_SET(1)

#	if ANKI_COMPUTE_SHADER
[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
#	else
RVec4 main(Vec2 uv : TEXCOORD, Vec4 svPosition : SV_POSITION) : SV_TARGET0
#	endif
{
#	if ANKI_COMPUTE_SHADER
	const Vec2 uv = (Vec2(svDispatchThreadId) + 0.5f) / g_consts.m_viewportSizef;
#	else
	const UVec2 svDispatchThreadId = UVec2(svPosition.xy);
#	endif

	// Read part of the G-buffer
	const RF32 roughness = unpackRoughnessFromGBuffer(g_gbufferRt1.SampleLevel(g_trilinearClampSampler, uv, 0.0));
	const Vec3 worldNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, uv, 0.0));

	// Get depth
	const F32 depth = g_depthRt.SampleLevel(g_trilinearClampSampler, uv, 0.0).r;

	// Rand idx
	const RVec2 noise2 = spatioTemporalNoise(svDispatchThreadId, g_consts.m_frameCount);

	// Get view pos
	const Vec3 viewPos = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(uv), depth);

	// Compute refl vector
	const Vec3 viewDir = -normalize(viewPos);
	const Vec3 viewNormal = mul(g_consts.m_normalMat, Vec4(worldNormal, 0.0));
	const Vec3 reflDir = reflect(-viewDir, viewNormal);

	// Is rough enough to deserve SSR?
	RF32 ssrAttenuation = saturate(1.0f - pow(roughness / g_consts.m_roughnessCutoff, 16.0f));

	// Do the heavy work
	Vec3 hitPoint;
	Vec3 hitPointViewSpace;
	if(ssrAttenuation > kEpsilonF32)
	{
		const U32 lod = 8u; // Use the max LOD for ray marching
		const U32 stepIncrement = g_consts.m_stepIncrement;
		const F32 stepIncrementf = F32(stepIncrement);
		const F32 minStepf = min(4.0f, stepIncrementf);
		const U32 initialStepIncrement = U32(lerp(minStepf, stepIncrementf, noise2.x));
		RF32 hitAttenuation;
		raymarchGroundTruth(viewPos, reflDir, uv, depth, g_consts.m_projMat00_11_22_23, g_consts.m_maxIterations, g_depthRt, g_trilinearClampSampler,
							F32(lod), stepIncrement, initialStepIncrement, hitPoint, hitAttenuation);

		ssrAttenuation *= hitAttenuation;

		// Compute the hit point in viewspace
		const F32 depth = g_depthRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).r;
		hitPointViewSpace = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(hitPoint.xy), depth);
	}
	else
	{
		ssrAttenuation = 0.0f;
	}

#	if EXTRA_REJECTION
	// Reject backfacing
	[branch] if(ssrAttenuation > 0.0)
	{
		const Vec3 gbufferNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0));
		const Vec3 hitNormal = mul(g_consts.m_normalMat, Vec4(gbufferNormal, 0.0));
		RF32 backFaceAttenuation;
		rejectBackFaces(reflDir, hitNormal, backFaceAttenuation);

		ssrAttenuation *= backFaceAttenuation;
	}

	// Reject far from hit point
	[branch] if(ssrAttenuation > 0.0)
	{
		const Vec3 reflRayHitPointVSpace = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(hitPoint.xy), hitPoint.z);

		const RF32 rejectionMeters = 0.5f;
		const RF32 diff = length(reflRayHitPointVSpace - hitPointViewSpace);
		const RF32 distAttenuation = 1.0f - smoothstep(0.0f, rejectionMeters, diff);
		ssrAttenuation *= distAttenuation;
	}
#	endif

	// Read the reflection
	RVec3 outColor = 0.0;
	[branch] if(ssrAttenuation > 0.0)
	{
		// Compute the LOD based on the roughness' cone
		Vec2 lightShadingTexSize;
		g_lightBufferRt.GetDimensions(lightShadingTexSize.x, lightShadingTexSize.y);

		const RF32 adjacentLen = length(hitPointViewSpace - viewPos);
		const RF32 coneAngle = pow(roughness - kMinRoughness, 4.0) * kPi / 4.0f; // Not physically correct
		const RF32 oppositeLen = tan(coneAngle / 2.0f) * adjacentLen;
		const Vec3 projectedOpposite =
			cheapPerspectiveProjection(g_consts.m_projMat00_11_22_23, Vec4(hitPointViewSpace + Vec3(oppositeLen, 0.0f, 0.0f), 1.0f));
		const F32 uvDistance = abs(ndcToUv(projectedOpposite.x) - hitPoint.x);
		const RF32 mip = max(0.0f, log2(uvDistance * lightShadingTexSize.x + kEpsilonF32));

		// Reproject the hit point because you are reading the previous frame
		const Vec4 v4 = mul(g_consts.m_prevViewProjMatMulInvViewProjMat, Vec4(uvToNdc(hitPoint.xy), hitPoint.z, 1.0));
		hitPoint.xy = ndcToUv(v4.xy / v4.w);

		// Read the light buffer
		RVec3 ssrColor = g_lightBufferRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, mip).rgb;
		ssrColor = clamp(ssrColor, 0.0, kMaxRF32); // Fix the value just in case

		outColor = ssrColor;
	}

	// Store
	ssrAttenuation = saturate(ssrAttenuation);
#	if ANKI_COMPUTE_SHADER
	g_outUav[svDispatchThreadId] = RVec4(outColor, ssrAttenuation);
#	else
	return RVec4(outColor, ssrAttenuation);
#	endif
}

#endif // ANKI_TECHNIQUE_Ssr && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)

// ===========================================================================
// Light shading downscale                                                   =
// ===========================================================================
#if ANKI_TECHNIQUE_MipGeneration && ANKI_COMPUTE_SHADER
struct Constants
{
	Vec2 m_invSrcTexSize;
	U32 m_threadGroupCount;
	U32 m_mipmapCount;
};

[[vk::push_constant]] ConstantBuffer<Constants> g_consts;

[[vk::binding(0)]] globallycoherent RWTexture2D<Vec4> g_dstUavs[kMaxMipsSinglePassDownsamplerCanProduce];
[[vk::binding(1)]] globallycoherent RWStructuredBuffer<U32> g_spdCounter;
[[vk::binding(2)]] Texture2D<Vec4> g_srcTex;

[[vk::binding(3)]] SamplerState g_linearAnyClampSampler;

// Include SPD
#	define A_GPU 1
#	define A_HLSL 1
#	include <ThirdParty/FidelityFX/ffx_a.h>

groupshared AU1 s_spdCounter;
groupshared AF3 s_spdIntermediateRgb[16][16];

AF4 SpdLoadSourceImage(AU2 p, AU1 slice)
{
	ANKI_MAYBE_UNUSED(slice);
	const AF2 uv = p * g_consts.m_invSrcTexSize + g_consts.m_invSrcTexSize;

	const Vec3 val = g_srcTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0).xyz;
	return AF4(val, 0.0f);
}

AF4 SpdLoad(AU2 p, AU1 slice)
{
	ANKI_MAYBE_UNUSED(slice);
	return AF4(g_dstUavs[5][p].xyz, 0.0);
}

void SpdStore(AU2 p, AF4 value, AU1 mip, AU1 slice)
{
	ANKI_MAYBE_UNUSED(slice);
	g_dstUavs[mip][p] = Vec4(value.xyz, 0.0f);
}

void SpdIncreaseAtomicCounter(AU1 slice)
{
	ANKI_MAYBE_UNUSED(slice);
	InterlockedAdd(g_spdCounter[0], 1u, s_spdCounter);
}

AU1 SpdGetAtomicCounter()
{
	return s_spdCounter;
}

void SpdResetAtomicCounter(AU1 slice)
{
	ANKI_MAYBE_UNUSED(slice);
	g_spdCounter[0] = 0u;
}

AF4 SpdLoadIntermediate(AU1 x, AU1 y)
{
	return AF4(s_spdIntermediateRgb[x][y], 0.0f);
}

void SpdStoreIntermediate(AU1 x, AU1 y, AF4 value)
{
	s_spdIntermediateRgb[x][y] = value.xyz;
}

AF4 SpdReduce4(AF4 v0, AF4 v1, AF4 v2, AF4 v3)
{
	AF4 value = v0 / 4.0f;
	value += v1 / 4.0f;
	value += v2 / 4.0f;
	value += v3 / 4.0f;
	return AF4(value.xyz, 0.0f);
}

#	define SPD_LINEAR_SAMPLER 1
#	include <ThirdParty/FidelityFX/ffx_spd.h>

[numthreads(256, 1, 1)] void main(UVec3 svGroupId : SV_GROUPID, U32 svGroupIndex : SV_GROUPINDEX)
{
	const U32 slice = 0u;
	const UVec2 offset = UVec2(0, 0);
	SpdDownsample(AU2(svGroupId.xy), AU1(svGroupIndex), AU1(g_consts.m_mipmapCount), AU1(g_consts.m_threadGroupCount), slice, offset);
}
#endif

// ===========================================================================
// Techniques                                                                =
// ===========================================================================
#pragma anki technique_start vert Ssr
#include <AnKi/Shaders/QuadVert.hlsl>
#pragma anki technique_end vert Ssr

#pragma anki technique_start frag Ssr
#pragma anki technique_end frag Ssr

#pragma anki technique_start comp Ssr
#pragma anki technique_end comp Ssr

#pragma anki technique_start comp MipGeneration
#pragma anki technique_end comp MipGeneration
